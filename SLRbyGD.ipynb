{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPpBfd4vgmRn4StI/3C95gF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BernieT7/ML/blob/main/SLRbyGD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1J2sXgyw8VZa",
        "outputId": "3eaa65fc-6045-4ab4-9ffc-a2f45848709c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9656 sha256=860c4fe157eb650d516a2f058a8088254c285d5e7b0acd94fd3b3fe53294f3e3\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/f1/7f/5c94f0a7a505ca1c81cd1d9208ae2064675d97582078e6c769\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ]
        }
      ],
      "source": [
        "!pip install wget\n",
        "import wget\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "from matplotlib.font_manager import fontManager\n",
        "\n",
        "wget.download(\"https://github.com/GrandmaCan/ML/raw/main/Resgression/ChineseFont.ttf\")\n",
        "fontManager.addfont(\"ChineseFont.ttf\")\n",
        "mpl.rc('font', family=\"ChineseFont\")\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/GrandmaCan/ML/main/Resgression/Salary_Data.csv\"\n",
        "data = pd.read_csv(url)\n",
        "x = data[\"YearsExperience\"]\n",
        "y = data[\"Salary\"]\n",
        "\n",
        "def compute_cost(x, y, w, b):\n",
        "  cost = (w * x + b - y) ** 2\n",
        "  cost = cost.mean()\n",
        "  return cost\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_gradient(x, y, w, b):\n",
        "  w_gradient = (2*(w * x + b -y)*x).mean()\n",
        "  b_gradient = (2*(w * x + b - y)).mean()\n",
        "  return w_gradient, b_gradient"
      ],
      "metadata": {
        "id": "w8Gdkj0pnMF_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w = 0\n",
        "b = 0\n",
        "learning_rate = 0.001\n",
        "\n",
        "def gradient_descent(x, y, w_init, b_init, learning_rate, cost_function, gradient_function, iter_time, per_iter=1000):\n",
        "\n",
        "  c_hist = []\n",
        "  w_hist = []\n",
        "  b_hist = []\n",
        "\n",
        "  w = w_init\n",
        "  b = b_init\n",
        "\n",
        "  for i in range(iter_time):\n",
        "    w_gradient, b_gradient = gradient_function(x, y, w, b)\n",
        "    w = w - w_gradient*learning_rate\n",
        "    b = b - b_gradient*learning_rate\n",
        "    cost = cost_function(x, y, w, b)\n",
        "\n",
        "    w_hist.append(w)\n",
        "    b_hist.append(b)\n",
        "    c_hist.append(cost)\n",
        "\n",
        "    if (i % per_iter) == 0:\n",
        "      print(f\"Iteration {i:5}: Cost{cost: .4e}, where w={w: .2e}, b={b: .2e}, w_gradient={w_gradient: .2e}, b_gradient={b_gradient: .2e}\")\n",
        "\n",
        "  return w, b, w_hist, b_hist, c_hist"
      ],
      "metadata": {
        "id": "a8R9Ed1HoS7x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w_init = 0\n",
        "b_init = 0\n",
        "learning_rate = 0.001\n",
        "iter_time = 20001\n",
        "\n",
        "w_final, b_final, w_hist, b_hist, c_hist = gradient_descent(x, y, w_init, b_init, learning_rate, compute_cost, compute_gradient, iter_time, per_iter=1000)\n",
        "print(f\"最終w={w_final:2f}, b={b_final:2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RuCCBsp3tdSg",
        "outputId": "b8cf5ad7-9bad-404f-efb6-ce7520db3901"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration     0: Cost 5.2861e+03, where w= 8.72e-01, b= 1.45e-01, w_gradient=-8.72e+02, b_gradient=-1.45e+02\n",
            "Iteration  1000: Cost 9.6020e+01, where w= 1.14e+01, b= 1.27e+01, w_gradient= 1.22e+00, b_gradient=-8.15e+00\n",
            "Iteration  2000: Cost 5.4275e+01, where w= 1.05e+01, b= 1.91e+01, w_gradient= 7.18e-01, b_gradient=-4.78e+00\n",
            "Iteration  3000: Cost 3.9926e+01, where w= 9.91e+00, b= 2.28e+01, w_gradient= 4.21e-01, b_gradient=-2.80e+00\n",
            "Iteration  4000: Cost 3.4993e+01, where w= 9.59e+00, b= 2.49e+01, w_gradient= 2.47e-01, b_gradient=-1.64e+00\n",
            "Iteration  5000: Cost 3.3298e+01, where w= 9.39e+00, b= 2.62e+01, w_gradient= 1.45e-01, b_gradient=-9.63e-01\n",
            "Iteration  6000: Cost 3.2715e+01, where w= 9.28e+00, b= 2.70e+01, w_gradient= 8.48e-02, b_gradient=-5.65e-01\n",
            "Iteration  7000: Cost 3.2515e+01, where w= 9.22e+00, b= 2.74e+01, w_gradient= 4.97e-02, b_gradient=-3.31e-01\n",
            "Iteration  8000: Cost 3.2446e+01, where w= 9.18e+00, b= 2.76e+01, w_gradient= 2.92e-02, b_gradient=-1.94e-01\n",
            "Iteration  9000: Cost 3.2422e+01, where w= 9.16e+00, b= 2.78e+01, w_gradient= 1.71e-02, b_gradient=-1.14e-01\n",
            "Iteration 10000: Cost 3.2414e+01, where w= 9.14e+00, b= 2.79e+01, w_gradient= 1.00e-02, b_gradient=-6.67e-02\n",
            "Iteration 11000: Cost 3.2411e+01, where w= 9.13e+00, b= 2.79e+01, w_gradient= 5.88e-03, b_gradient=-3.91e-02\n",
            "Iteration 12000: Cost 3.2410e+01, where w= 9.13e+00, b= 2.80e+01, w_gradient= 3.45e-03, b_gradient=-2.29e-02\n",
            "Iteration 13000: Cost 3.2410e+01, where w= 9.13e+00, b= 2.80e+01, w_gradient= 2.02e-03, b_gradient=-1.35e-02\n",
            "Iteration 14000: Cost 3.2410e+01, where w= 9.13e+00, b= 2.80e+01, w_gradient= 1.18e-03, b_gradient=-7.89e-03\n",
            "Iteration 15000: Cost 3.2410e+01, where w= 9.13e+00, b= 2.80e+01, w_gradient= 6.94e-04, b_gradient=-4.62e-03\n",
            "Iteration 16000: Cost 3.2410e+01, where w= 9.12e+00, b= 2.80e+01, w_gradient= 4.07e-04, b_gradient=-2.71e-03\n",
            "Iteration 17000: Cost 3.2410e+01, where w= 9.12e+00, b= 2.80e+01, w_gradient= 2.39e-04, b_gradient=-1.59e-03\n",
            "Iteration 18000: Cost 3.2410e+01, where w= 9.12e+00, b= 2.80e+01, w_gradient= 1.40e-04, b_gradient=-9.32e-04\n",
            "Iteration 19000: Cost 3.2410e+01, where w= 9.12e+00, b= 2.80e+01, w_gradient= 8.20e-05, b_gradient=-5.46e-04\n",
            "Iteration 20000: Cost 3.2410e+01, where w= 9.12e+00, b= 2.80e+01, w_gradient= 4.81e-05, b_gradient=-3.20e-04\n",
            "最終w=9.123829, b=28.010479\n"
          ]
        }
      ]
    }
  ]
}